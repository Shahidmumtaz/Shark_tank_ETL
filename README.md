# Shark_tank_ETL

Extract

The first task in my data analysis was to extract the data from more than one primary datasource. The primary datasource for this project was: Kaggle and data.world

I retrieved the Shark Tank data from Kaggle and data.world. The data was already in CSV format when downloaded, so I didn't need to convert the data into any other format. 

Transform

Basic transformation:

Cleaning: Removing null values from the rows and columns.

Deduplication: Identifying and removing duplicate records.


Advanced transformations:

Filtering: Selecting only certain rows and/or columns helped me organize the dataset and show the data that I wanted to work with.

Joining: Linking data from multiple sources â€“ for example from kaggle and data.world into mySQL.

Sorting:  Sorting values in a descending order to show highest valuations.
    
Aggregation: Data elements are aggregated from multiple data sources and databases to dataframes and tables.

Integration: Give each unique data element one standard name. Data integration reconciles different data names and values for the same data element.


Final Analysis
For the final analysis I used MySql. Because it is easy to load the data as it is a relational database and is easily accessible and convertible.

The expected outcomes for this project if we would go into the next step of analysing the data, would be to find a relation between categories and highest valuations and deals. For example we could find which category of products/services has so far attracted the sharks most and motivated them to invest their money on.  Furthermore, we could find which shark has invested in ideas more-which shark is in the lead.

Most importantly, the analysis derived from this data could be a lead to those targeting the sharks or planning to present their ideas, products or services in the Shark Tank Show.  The data analysis could show a trend between the deals, categories and seasons.
